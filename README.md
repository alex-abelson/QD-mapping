
# Mapping, defect classification, and structural quantification of nanoparticle (NP) superlattice images.

## Alex Abelson, PhD
## alexabelson9@gmail.com


### Description
This software package takes electron microscopy images of NP superlattices and generates a series of useful graphical and numerical outputs. There are three key components: 

1. Identify the x,y position of NPs in the image. This is achieved using two separate steps:
 - a) First, NPs are coarsely identified using a blob-detection algorithm in Sci-Kit image.  
 - b) Second, the position is refined to sub-pixel resolution using a simple 2D Gaussian fitting approach (SciPy Optimize Package; convert 2D to 1D and use a least squares algorithm). 

2. Calculate the Voronoi decomposition of the NP array (SciPy Spatial Package). From this, a variety of local SL structural metrics can be extracted and catalogued for each NP in the image. The Voronoi decomp. is the key computational tool that enables quantification of the local SL structure.

3. Classify NPs in the image based on various attributes of their local SL structure. This is accomplished using a SciKit-Learn Clustering package (DBSCAN). The input design matrix contains features generated by the Voronoi decomposition.

### Key Outputs: 
Quantitative or graphical information can be extracted from either all NPs, or individual NP classes.

### Key Challenges: 
There are a variety of ways of evaluating the structural order/disorder of a lattice. Additional functionalities can be added, although inter-dependencies between the three main components of the program necessitate care in adding or removing functionality.

### Required packages:
- Python 3.0 and higher.
- Matplotlib
- Scipy
- Sci-kit Learn

 *These all come standard if you have the Anaconda Distrbution Platform. I run my code through the Anaconda prompt.

### How to install and run the project: 
1. Download the library of python scripts and save them to a folder on your computer.
2. Open the script titled 'runfile.py' and make any necessary settings changes (vide infra). 
3. Navigate in the Anaconda prompt to the folder containing the scripts, then run: 
```bash
python runfile.py
```


### Scripts:

_The software is designed so that there are 4 scripts (Scripts 1-4) that contain functions that never need user input. One should almost never need to open those scripts to modify the code. All of the user input and the actual flow of code is contained in runfile.py. Running scripts 1-4 alone results in no output._

#### Script 1. findParticles.py
- Contains a single function responsible for the identification of particles with single-pixel resolution (Step 1a).

#### Script 2. subpixel.py
- Calculates the subpixel position of NPs, starting with the output from Script 1 as an initial guess.

#### Script 3. designMatrix.py
- Performs the Voronoi decomposition, then extracts structural metrics and returns them as the outputs of various functions. Descriptions of the various functions and their outputs are provided in-code.

#### Script 4. clusterAnalysis.py
- Classifies particles in the images based on their structural feature values.

#### Script 5. runfile.py
- Contains the run functionality of the code; brings together components from Scripts 1-4 to actually do the whole process. See below.

## The Runfile (runfile.py)
When running code, all modifications are made in the runfile.py script. 

### Runfile Functions
**All of the variables used in the runfile functions are specified manually at the top of runfile.py. The purpose of these variables are defined below.**

_If there are variables repeated in multiple functions, they are only defined in the top function._

#### Particles(filename, x_size, y_size, ShowBlobs, min_sigma, max_sigma, threshold)
- **Inputs**:
  - _filename_: image file path
  - _x_size_: number of pixels in x dimension
  - _y_size_: number of pixels in y dimension
  - _ShowBlobs_: IF you want to show the resulting image
  - _min_sigma_: smallest size of blob radius for coarse NP fitting
  - _max_sigma_: largest size of blob radius for coarse NP fitting
  - _threshold_: setting for blob detection; Lower threshold means higher susceptibility to noise.
- **Outputs**:
  - _blobs_out_: 2D numpy array with x,y coordinates of each NP
- **Save To Drive**:
  - nothing

#### Subpixel(directory, filename, centroids, x_size, y_size, conversion, spacing, ShowSubpixels)
- **Inputs**: 
  - _directory_: image folder path (why is this in here?)
  - _centroids_: 2D numpy array with x,y coordinates of each NP
  - _conversion_: float value that converts pixels into true distance (pixels/nm)
  - _spacing_: sets the size of the window used for sub-pixel fitting of each particle
  - _ShowSubpixels_: IF you want to show each NP fitting (~10000 per image; ill-advised)
- **Outputs**:
  - _new_centroids_: 2D numpy array with x,y positions of NPs with subpixel precision
- **Save to Drive**:
  - _new_centroids_: .npz; see above description

#### MakeDesignMatrix(directory, filename,centroids,x_size, y_size, ShowVoronoi)
- **Description**: This function first calls on functions within designMatrix.py to instantiate both the Voronoi decomposition and structural metrics as local variables. The latter are then compiled into a new array (the design matrix), and returned from this function. There is an additional step in which edge particles are removed from the design matrix.
- **Inputs**: 
  - _centroids_: 2D numpy array with x,y positions of NPs (output either from Particles() or Subpixel())
  - _ShowVoronoi_: IF you want to show the Voronoi diagram for each image in the folder
- **Outputs**:
  - _DesignMatrix_: complete design matrix with edge particles removed, ready for clustering
- **Save to Drive**:
  - _distances_: .txt; a 1D array containing all of the distances for nearest neighbors within an image
  - _distance_diffs_: .txt; a 1D array containing all of the differences between the two closest NNs for each NP
  - _designmatrix_: .txt and .npz; a 2D array containing the full design matrix

#### Clustering(directory, filename, DesignMatrixTemp, x_size, y_size, ShowCluster)
- **Description**: This function prepares the design matrix by calling on functions that normalize the design matrix and then do the actual classification of particles.
- **Inputs**:
  - _DesignMatrixTemp_: the 2D numpy array containing the design matrix, which is pulled from an .npz file
  - _ShowCluster_: IF you want to produce the classified image and save the graphic
- **Outputs**:
  - none
- **Save To Drive**:
  - _labels_: .txt and .npz; labels for each of the particles 

### General Runfile Parameters and Operation
The actual operation of the code is simplified into a series of _if_ statements at the bottom of runfile.py. These _if_ statements control which of the above functions actually run when the code is executed. It is divided so that you can , for example, identify only the particle locations for a series of images. The following inputs are set at the top of runfile.py to determine what functions are performed upon execution of the code.

```python
CentroidsRun = False #Turns on and off the particle fitting code.
DesignMatrixRun = False #Turns on and off the design matrix part of the code.
ClusterRun = True #Turns on and off the clustering part of the code.
CleanDesignMatrix = True #Turns on and off the removal of defective NPs from the final design matrix, from which you extract structural metrics.
directory = r'C:/Users/Alex/Desktop/SEM Image Analysis Photobase/PBG z gradient check/' #Folder containing the images.
sizeSet = True #Turns on and off auto-sizing. If True, will determine the image size from the image itself. Otherwise, uses x,y sizes below
x_size = int(1536)
y_size = int(1024)
```

**Again, depending on which of the above parameters are set to True or False, upon execution of the code, those operations will run. Each of these _if_ statements is capable of running alone because the necessary function inputs are loaded from .npz files rather than being stored as local variables.**


# Technical Description

## Particle Fitting
Particle fitting is done in 2 steps. The first uses Sci-Kit Image's Laplacian of Gaussian algorithm. More information can be found [here](https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_blob.html). The only variable that I had hard-wired into the function is the number of NP sizes that it tries to fit within the range between _min_sigma_ and _max_sigma_ (I have it set to 4). The seconds step of the fitting is doing the subpixel routine. This code was adapted from Ben Savitzky's code which can be found [here](https://github.com/bsavitzky/rdf). In short, this code moves around to different NPs in the image. At a particular location, it defines a sub-section of the image to use for fitting (typically around 90% of the nearest-neighbor distance), then unravels that small image into a 1D array. This 1D array is then fit with a Gaussian function, and the position of the Gaussian is used to determine the actual centroid of the NP. Apparently this method is faster than doing a true 2D fit. It seems to work pretty well.

## Design Matrix
In the design matrix code there is a lot of fiddling around required to generate the structural parameters (nearest-neighbor distances, etc.). Much of this is just a matter of wrestling with the computational form of the [Voronoi decomposition](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.Voronoi.html). These structural parameters are below. Note that the first three columns of the design matrix are: 1) particle index, 2) x position, and 3) y position and are removed in clustering. The parameters that are bolded are actually used in the current design matrix, but they can be removed or added at will.
**Structural Parameters**

- Distances between a NP and all of its neighbors
- **Average nearest neighbor distance**
- Standard deviation in nearest neighbor distance
- Closest nearest neighbor distance
- Difference in distance between two closest nearest neighbors
- **Number of nearest neighbors**
- Area of the Voronoi cell
- **Psi4 and Psi6 (bond order parameters, see [this](https://pubs.acs.org/doi/10.1021/acsnano.9b04951))**
- **Complex arguments of Psi4 and Psi6**

## Clustering
The clustering is done using a [density-based clustering algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) from Sci-Kit Learn. First, the design matrix is prepared by normalizing (standardizing) each feature space using the SKLearn [standard scaler function](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Next, the optimal epsilon value (the only parameter for DBSCAN) is selected using an algorithmic [method](https://bit.ly/3Ck7KUv) which determines the point of maximum curvature for the distance vs. index curve. It's abstract and you need to read about clustering analysis and this particular epsilon-setting method if you want to understand more detail. In short, this algorithm sets epsilon to best define the clusters. Next, the standardized design matrix is fed into the DBSCAN algorithm using the calculated epsilon value, and the particle labels are generated. DBSCAN produces an abritrary number of classes, and includes noise points (label = -1) for NPs with unique local SL structures. This whole clustering thing can likely be improved by 1) varying the input design matrix and 2) optimizing the actual clustering method.

# Acknowledgements
This project was conceived of and developed while working in the laboratory of Matt Law at UC Irvine. Caroline Qian provided many of the images used to validate the software.



 

	
